{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2753a9e4",
   "metadata": {},
   "source": [
    "# Live Demo\n",
    "\n",
    "You can try this feature with your won data in this page. \n",
    "\n",
    "Fulfill the cell below and run it to see the result:\n",
    "* `title`: the title of your dataset\n",
    "* `description`: description of your dataset\n",
    "* `resource_names`: file names in your dataset\n",
    "* `resource_descriptions`: the description of files in your dataset\n",
    "* `organization_title`: the tilte of the affiliatedorganization \n",
    "* `organization_description`: the description of the affiliatedorganization \n",
    "\n",
    "```{warning} Notice\n",
    "At least one of the fields should be completed. Leaving all of them empty is not permissible.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4e619c3",
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hostedtoolcache/Python/3.8.17/x64/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Packages Import ============================================================\n",
    "import requests\n",
    "\n",
    "# Import model\n",
    "from transformers import (\n",
    "   BertTokenizerFast,\n",
    "   AutoModelForMaskedLM,\n",
    "   AutoModelForCausalLM,\n",
    "   AutoModelForTokenClassification,\n",
    ")\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-chinese')\n",
    "model = AutoModelForTokenClassification.from_pretrained('ckiplab/bert-tiny-chinese-ner')\n",
    "\n",
    "# NLP task model\n",
    "from ckip_transformers.nlp import CkipWordSegmenter, CkipPosTagger, CkipNerChunker\n",
    "ws_driver  = CkipWordSegmenter(model=\"bert-base\")\n",
    "pos_driver = CkipPosTagger(model=\"bert-base\")\n",
    "ner_driver = CkipNerChunker(model=\"bert-base\")\n",
    "\n",
    "# Function Definstion =========================================================\n",
    "def wiki_search(search_term):\n",
    "    url = f\"https://www.wikidata.org/w/api.php?action=wbsearchentities&format=json&search={search_term}&language=zh\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    # organize the response\n",
    "    if \"search\" in data:\n",
    "        for result in data[\"search\"]:\n",
    "            qid = result[\"id\"]\n",
    "            label = result[\"label\"]\n",
    "            description = result.get(\"description\", \"No description available\")\n",
    "            print(f\"QID: {qid}, Label: {label}, Description: {description}\")\n",
    "    else:\n",
    "        print(\"No results found.\")\n",
    "\n",
    "def make_keyword_map(input_list):\n",
    "    # NER task\n",
    "    ner = ner_driver(input_list)\n",
    "\n",
    "    # Build keyword_map to store potential words\n",
    "    avoid_class = ['QUANTITY', 'CARDINAL', 'DATE', 'ORDINAL']\n",
    "    keyword_map = {}\n",
    "    for sentence_ner in ner:\n",
    "        for entity in sentence_ner:\n",
    "            if(entity[1] in avoid_class):\n",
    "                continue\n",
    "        keyword_map[entity[0]] = entity[1]\n",
    "    \n",
    "    return keyword_map\n",
    "\n",
    "def gen_keyword(title, description, resource_names, resource_descriptions, organization_title, organization_description):\n",
    "    input_list = [title, description, resource_names, resource_descriptions, organization_title, organization_description]\n",
    "\n",
    "    if not all(item for item in input_list):\n",
    "        return -1\n",
    "    else:\n",
    "       keyword_map = make_keyword_map(input_list)\n",
    "       return keyword_map\n",
    "\n",
    "def output(result):\n",
    "    if(result == -1):\n",
    "        print(\"At least one of the fields should be completed. Leaving all of them empty is not permissible.\")\n",
    "    else:\n",
    "        for item in keyword_map:\n",
    "            print(item)\n",
    "            wiki_search(item)\n",
    "            print('-------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707f9d51",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ded6777",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "title = ''\n",
    "description = ''\n",
    "resource_names = []\n",
    "resource_descriptions = []\n",
    "organization_title = \"\"\n",
    "organization_description = \"\"\n",
    "\n",
    "result = gen_keyword(title, description, resource_names, resource_descriptions, organization_title, organization_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e39aec",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9103e858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At least one of the fields should be completed. Leaving all of them empty is not permissible.\n"
     ]
    }
   ],
   "source": [
    "output(result)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.15.1"
   }
  },
  "kernelspec": {
   "display_name": "2023-sinica-intern",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "source_map": [
   12,
   30,
   101,
   105,
   116,
   120
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}